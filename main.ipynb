{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"./images/test_2.jpg\")\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "\n",
    "ratio = 0.2  # Make it smaller for easy processing\n",
    "width = int(ratio * width)\n",
    "height = int(ratio * height)\n",
    "orig = image.copy()\n",
    "orig_resized = imutils.resize(image, height=height)\n",
    "image = imutils.resize(image, height=height)\n",
    "cv2.imshow(\"Image\",image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn it to Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Strategy #1\n",
    "# gray_scaled = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Blur to smoothen out and remove unnecessary pixels\n",
    "# gray_scaled = cv2.GaussianBlur(gray_scaled,(5,5),0)  \n",
    "\n",
    "\n",
    "#Strategy #2\n",
    "gray_scaled = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_scaled = cv2.GaussianBlur(gray_scaled, (7,7), 0)\n",
    "\n",
    "# dilate helps to remove potential holes between edge segments\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(9,9))\n",
    "dilated = cv2.morphologyEx(gray_scaled, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "\n",
    "# Find the edges if use, strategy #1 change dilated to gray_scaled\n",
    "edged_img = cv2.Canny(dilated,0,84)\n",
    "\n",
    "cv2.imshow(\"Edges\",edged_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Countours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETR LIST IS BETTER\n",
    "# Find contours based on OpenCV version\n",
    "contours, hierarchy = cv2.findContours(edged_img.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "if len(contours) == 3:\n",
    "    contours = contours[0]  # If OpenCV 3.x, we extract the first element (contours)\n",
    "\n",
    "# Now grab the contours using imutils\n",
    "contours = imutils.grab_contours((contours, hierarchy))\n",
    "\n",
    "# Sort the contours based on size and pick the top 5\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "# loop over the contours\n",
    "paper_outline = None\n",
    "for contour in contours:\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    # approximate the contour\n",
    "    approximation = cv2.approxPolyDP(contour, 0.01 * perimeter, True)\n",
    "\n",
    "    # if our contour has 4 points, then surely, it should be the paper\n",
    "    if len(approximation) == 4:\n",
    "        paper_outline = approximation\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.drawContours(image,[paper_outline],-1,(255,255,0),2)  \n",
    "cv2.imshow(\"Found outline\", image)  \n",
    "cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Corner Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(points):\n",
    "   # initialize a list of co-ordinates that will be ordered\n",
    "   rectangle = np.zeros((4, 2), dtype=\"float32\")\n",
    "   sum_points = points.sum(axis=1)\n",
    "   rectangle[0] = points[np.argmin(sum_points)]  # top-left\n",
    "   rectangle[2] = points[np.argmax(sum_points)]  # bottom-right\n",
    "   diff_points = np.diff(points, axis=1)\n",
    "   rectangle[1] = points[np.argmin(diff_points)]  # top-right\n",
    "   rectangle[3] = points[np.argmax(diff_points)]  # bottom-left\n",
    "   return rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warp the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_four_points(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width and height of the new image\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    transform_matrix = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, transform_matrix, (maxWidth, maxHeight))\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Reset in progress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize points to match the original image size\n",
    "test_points = order_points(paper_outline.reshape(4, 2) * (1 / ratio))\n",
    "\n",
    "warped = set_four_points(orig, paper_outline.reshape(4, 2) * (1 / ratio))\n",
    "\n",
    "print(\"Image Reset in progress\")\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhance the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def enhance_image(warped):\n",
    "    # 1. Adjust contrast\n",
    "    # We can scale the pixel values to increase contrast.\n",
    "    contrast_factor = 1.2  # Increase this value to increase contrast further\n",
    "    enhanced_contrast = cv2.convertScaleAbs(warped, alpha=contrast_factor, beta=0)\n",
    "    \n",
    "    # 2. Adjust brightness\n",
    "    # We can apply a brightness shift (e.g., decrease brightness for better text clarity).\n",
    "    brightness_factor = -20  # You can adjust this value to lighten or darken the image\n",
    "    adjusted_brightness = cv2.convertScaleAbs(enhanced_contrast, alpha=1, beta=brightness_factor)\n",
    "    \n",
    "    saturation_factor = 1.5\n",
    "    # 1. Convert the image from BGR to HSV\n",
    "    hsv = cv2.cvtColor(adjusted_brightness, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 2. Increase saturation by multiplying the saturation channel (index 1) by a factor\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    \n",
    "    # Increase the saturation\n",
    "    s = cv2.multiply(s, saturation_factor)\n",
    "    s = np.clip(s, 0, 255)  # Ensure the values stay within the valid range [0, 255]\n",
    "    \n",
    "    # 3. Merge the channels back\n",
    "    hsv_enhanced = cv2.merge([h, s, v])\n",
    "    \n",
    "    # 4. Convert back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return enhanced_image\n",
    "# Enhance the warped image\n",
    "enhanced_warped = enhance_image(warped)\n",
    "\n",
    "# Show the original and enhanced images\n",
    "cv2.imshow(\"Original Warped Image\", imutils.resize(warped, height))\n",
    "cv2.imshow(\"Enhanced Warped Image\", imutils.resize(enhanced_warped, height))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "Mooncake / Mid-Autumn Festival\n",
      "\n",
      "The moon 1a the fulieat and beightost at the 15th day of the 8th month of the Lunar Cafendar known as thre\n",
      "Mid-Autumn (Moon) Festival, tt Is also a memorable day for the Chinese â€˜who overthrew thier tyrant ruler of\n",
      "\n",
      "the Yuan Dynasty known as Marce Polo.\n",
      "\n",
      "Duting thal ero, the people were ail unarmed pnd well guarded by one solder for avery three familles and\n",
      "they were obliged to maintain all necessities of the soldier.\n",
      "\n",
      "Due to the Imperietistic tactics of the tyrant the revolutionists tosh advantage of the full moon of\n",
      "Mid-Autumn. As all tamilina exseinble due te the festival, ney were able to circulate their propaganda\n",
      "mavement, (o revolt throughout the country thru the messages hidden Inside the mooncakes. Because of\n",
      "thia the soldiers were unawere snd caught by surprise hy the revolution that succeeded that brought about\n",
      "\n",
      "the Ning Dynasty in 1387.\n",
      "\n",
      "MECHANICS:\n",
      "\n",
      "â€˜You toll the dice, and you win a prize based on the dice combinations, which are named\n",
      "after Imporiat Uitas, Each player rolls one per tum, until all the prizes have been givenâ€™\n",
      "out. IN a dle rolts out of the bows, you Jose your firm.\n",
      "\n",
      "sont oate PRIZE CHART\n",
      "\n",
      "Ist PRIZE 4 Number 4â€™s or 5 of the same kind\n",
      ". 5 Number 4's Overrule any of the above winner to be determined by highest last die\n",
      "\n",
      "IKIt\n",
      "Ubss|ssfes|ss[ssf ss MR ss [se] ss Tet eel S|\n",
      "22S RRR + Bea eee\n",
      "Ryssiss|sspssass| Â° Massississpssf spss,\n",
      "rg :2 132122132 |23| >: nr\n",
      "2ND PRIZE fe fe] +f. |.\n",
      "\n",
      "BEAR / RIE 3 â€”\n",
      "\n",
      "HALF & HALF or 1 to 6 Fo Ped edsspepss| .\n",
      "\n",
      "3RD PRIZE 4 Scholars Optional Rule:___6 Number 4's\n",
      "S55 3 Number 4â€™s EMBARGO: (33][s2][32][23)(33](23]\n",
      "The ptayer will get the whole set of\n",
      "\n",
      "cakes even the oneâ€™s already taken by others\n",
      "\n",
      "ATH PRIZE 8 Scholars Go o | a Fa | | is\n",
      "\n",
      "Fiza\n",
      "4 of the same kind\n",
      "an ey ey ee SSqsspeeyes\n",
      "\n",
      "a PRIZE 33 | 33 | 6TH PRIZE\n",
      "2 Number 4â€™s FSA Number 4s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "def extract_text(warped_image):\n",
    "    # 1. Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(warped_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2. Apply thresholding to make the text stand out more (you can try different methods like Otsu's thresholding)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # 3. Optionally, apply additional preprocessing (e.g., noise reduction or dilation/erosion)\n",
    "    # For better results, you can use morphological operations like dilation\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    thresh = cv2.dilate(thresh, kernel, iterations=1)  # Optional step, depending on your image\n",
    "\n",
    "    # 4. Extract text using pytesseract\n",
    "    text = pytesseract.image_to_string(thresh)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Assuming 'warped' is the image you want to extract text from\n",
    "extracted_text = extract_text(enhanced_warped)\n",
    "\n",
    "# Print the extracted text\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_folder = \"./uploads\"\n",
    "if not os.path.exists(upload_folder):\n",
    "    os.makedirs(upload_folder)\n",
    "\n",
    "text_output_path = os.path.join(upload_folder,\"extracted_text.txt\")\n",
    "\n",
    "# Save the warped (scanned) image\n",
    "img_output_path = os.path.join(upload_folder, \"scanned_image.jpg\")\n",
    "cv2.imwrite(img_output_path, enhanced_warped)\n",
    "with open(text_output_path, \"w\") as file:\n",
    "    file.write(extracted_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
