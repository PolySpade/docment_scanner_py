{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"./images/test_4.jpg\")\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "\n",
    "ratio = 0.2  # Make it smaller for easy processing\n",
    "width = int(ratio * width)\n",
    "height = int(ratio * height)\n",
    "orig = image.copy()\n",
    "orig_resized = imutils.resize(image, height=height)\n",
    "image = imutils.resize(image, height=height)\n",
    "cv2.imshow(\"Image\",image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn it to Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # Strategy #1\n",
    "# gray_scaled = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Blur to smoothen out and remove unnecessary pixels\n",
    "# gray_scaled = cv2.GaussianBlur(gray_scaled,(5,5),0)  \n",
    "\n",
    "\n",
    "#Strategy #2\n",
    "gray_scaled = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Gray Scaled\",gray_scaled)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray_scaled = cv2.GaussianBlur(gray_scaled, (7,7), 0)\n",
    "\n",
    "cv2.imshow(\"Blurred Gray Scaled\",gray_scaled)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# dilate helps to remove potential holes between edge segments\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "\n",
    "dilated = cv2.morphologyEx(gray_scaled, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"Dilated\",dilated)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find the edges if use, strategy #1 change dilated to gray_scaled\n",
    "edged_img = cv2.Canny(dilated,0,84)\n",
    "\n",
    "cv2.imshow(\"Edges\",edged_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Countours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETR LIST IS BETTER\n",
    "contours, hierarchy = cv2.findContours(edged_img.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "if len(contours) == 3:\n",
    "    contours = contours[0] \n",
    "# Now grab the contours using imutils\n",
    "contours = imutils.grab_contours((contours, hierarchy))\n",
    "\n",
    "# Sort the contours based on size and pick the top 5\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "# loop over the contours\n",
    "paper_outline = None\n",
    "for contour in contours:\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.01 * perimeter, True)\n",
    "\n",
    "    # Filter contours by area\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area < 5000:  # Minimum area threshold\n",
    "        continue\n",
    "\n",
    "    # Check aspect ratio\n",
    "    x, y, w, h = cv2.boundingRect(approx)\n",
    "    aspect_ratio = float(w) / h\n",
    "    if 0.5 < aspect_ratio < 2.0 and len(approx) == 4:\n",
    "        paper_outline = approx\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.drawContours(image,[paper_outline],-1,(255,255,0),2)  \n",
    "cv2.imshow(\"Found outline\", image)  \n",
    "cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Corner Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(points):\n",
    "   # initialize a list of co-ordinates that will be ordered\n",
    "   rectangle = np.zeros((4, 2), dtype=\"float32\")\n",
    "   sum_points = points.sum(axis=1)\n",
    "   rectangle[0] = points[np.argmin(sum_points)]  # top-left\n",
    "   rectangle[2] = points[np.argmax(sum_points)]  # bottom-right\n",
    "   diff_points = np.diff(points, axis=1)\n",
    "   rectangle[1] = points[np.argmin(diff_points)]  # top-right\n",
    "   rectangle[3] = points[np.argmax(diff_points)]  # bottom-left\n",
    "   return rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warp the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_four_points(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width and height of the new image\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    transform_matrix = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, transform_matrix, (maxWidth, maxHeight))\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Reset in progress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warped = set_four_points(orig, paper_outline.reshape(4, 2) * (1 / ratio))\n",
    "\n",
    "print(\"Image Reset in progress\")\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhance the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def enhance_image(warped):\n",
    "    contrast_factor = 1.1  # Increase this value to increase contrast further\n",
    "    enhanced_contrast = cv2.convertScaleAbs(warped, alpha=contrast_factor, beta=0)\n",
    "    \n",
    "    brightness_factor = -5  # You can adjust this value to lighten or darken the image\n",
    "    adjusted_brightness = cv2.convertScaleAbs(enhanced_contrast, alpha=1, beta=brightness_factor)\n",
    "    \n",
    "    saturation_factor = 1.1\n",
    "    # 1. Convert the image from BGR to HSV\n",
    "    hsv = cv2.cvtColor(adjusted_brightness, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 2. Increase saturation by multiplying the saturation channel (index 1) by a factor\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    \n",
    "    # Increase the saturation\n",
    "    s = cv2.multiply(s, saturation_factor)\n",
    "    s = np.clip(s, 0, 255)  # Ensure the values stay within the valid range [0, 255]\n",
    "    \n",
    "    # 3. Merge the channels back\n",
    "    hsv_enhanced = cv2.merge([h, s, v])\n",
    "    \n",
    "    # 4. Convert back to BGR color space\n",
    "    enhanced_image = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return enhanced_image\n",
    "# Enhance the warped image\n",
    "enhanced_warped = enhance_image(warped)\n",
    "\n",
    "# Show the original and enhanced images\n",
    "cv2.imshow(\"Original Warped Image\", imutils.resize(warped, height))\n",
    "cv2.imshow(\"Enhanced Warped Image\", imutils.resize(enhanced_warped, height))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "Whats Lorem Ipsum?\n",
      "\n",
      "Forem Epsum is simply dummy text of the Poot and t pesetting madustry Lorem Epsum has\n",
      "been the industey's standard dummy text ever since the PS00s, when an unknown printer took a\n",
      "talles of type and scrambled it to make at pe specamen book Tt has survived not only five\n",
      "centuries, bit also the leap into electronic ts pesetting. rematning essentially unchanged. ft was\n",
      "popularised m the LOeOs with the release of Letraset sheets containing Lorem [psum passages,\n",
      "and mere recenth wath desktop publishing software like Aldus PageMaker including versions of\n",
      "\n",
      "Lorem Ipsum\n",
      "Whey do we use it?\n",
      "\n",
      "Its a long established fact that a reader will be distracted by the readable content of a page when\n",
      "looking at its layout The point of using Lorem Ipsum is that it has a more-or-less normal\n",
      "distribution of letters, as opposed to using \"Content here, content here’. making it look like\n",
      "readable English. Many desktop publishing packages and web page editors now use lorem\n",
      "Ipsum as then default model text, and a search for ‘lorem ipsum’ will uncover many web sites\n",
      "stim ther infaney. Various versions have evolved over the years, sometimes by accident.\n",
      "sometimes on purpose (ingected humour and the like),\n",
      "\n",
      "Where does 1 come from?\n",
      "\n",
      "Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of\n",
      "classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a\n",
      "Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure\n",
      "Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word\n",
      "in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections\n",
      "1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by\n",
      "Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the\n",
      "Renaissance. The first line of Lorem Ipsum, “Lorem ipsum dolor sit amet..\", comes from a line\n",
      "\n",
      "in section 1.10.32.\n",
      "The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those\n",
      "\n",
      "interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are\n",
      "also reproduced in their exact original form, accompanied by English versions from the 1914\n",
      "\n",
      "translation by H. Rackham.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "def extract_text(warped_image):\n",
    "    gray = cv2.cvtColor(warped_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    thresh = cv2.dilate(thresh, kernel, iterations=1)  # Optional step, depending on your image\n",
    "\n",
    "    text = pytesseract.image_to_string(thresh)\n",
    "\n",
    "    return text\n",
    "\n",
    "extracted_text = extract_text(enhanced_warped)\n",
    "\n",
    "# Print the extracted text\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_folder = \"./uploads\"\n",
    "if not os.path.exists(upload_folder):\n",
    "    os.makedirs(upload_folder)\n",
    "\n",
    "text_output_path = os.path.join(upload_folder,\"extracted_text.txt\")\n",
    "\n",
    "# Save the warped (scanned) image\n",
    "img_output_path = os.path.join(upload_folder, \"scanned_image.jpg\")\n",
    "cv2.imwrite(img_output_path, enhanced_warped)\n",
    "with open(text_output_path, \"w\") as file:\n",
    "    file.write(extracted_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
